{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start here! If you can directly link to an image relevant to your notebook, such as [canonical logos](https://github.com/numpy/numpy/blob/main/doc/source/_static/numpylogo.svg), do so here at the top of your notebook. You can do this with Markdown syntax,\n",
    "\n",
    "> `![<image title>](http://link.com/to/image.png \"image alt text\")`\n",
    "\n",
    "or edit this cell to see raw HTML `img` demonstration. This is preferred if you need to shrink your embedded image. **Either way be sure to include `alt` text for any embedded images to make your content more accessible.**\n",
    "\n",
    "<img src=\"images/ProjectPythia_Logo_Final-01-Blue.svg\" width=250 alt=\"Project Pythia Logo\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Argo Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Building upon previous notebook, [Introduction to Argo](notebooks/argo-introduction.ipynb), we next explore how to access Argo data using various methods.\n",
    "\n",
    "These methods are described in more detail on their respective websites, linked below. Our goal here is to provide a brief overview of some of the different tools available. \n",
    "\n",
    "1. [GO-BGC Toolbox](https://github.com/go-bgc/workshop-python) \n",
    "2. [Argopy](https://argopy.readthedocs.io/en/latest/user-guide/fetching-argo-data/index.html), a dedicated Python package\n",
    "3. [Argovis](https://argovis.colorado.edu/argo) for API-based queries \n",
    "\n",
    "<!-- 2. Downloading [monthly snapshots](http://www.argodatamgt.org/Access-to-data/Argo-DOI-Digital-Object-Identifier) using Argo DOI's -->\n",
    "<!-- 4. Using the [GO-BGC Toolbox](https://github.com/go-bgc/workshop-python) -->\n",
    "\n",
    "After going through this notebook, you will be able to retrieve Argo data of interest within a certain time frame, geographical location, or by platform identifier. There are many other ways of working with Argo data, so we encourage users to explore what applications work best for their needs. \n",
    "Further information on Argo access can be found on the [Argo website](https://argo.ucsd.edu/data/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Label the importance of each concept explicitly as **helpful/necessary**.\n",
    "\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Intro to Numpy](https://numpy.org/learn/) | Necessary | |\n",
    "| [Intro to NetCDF](https://foundations.projectpythia.org/core/data-formats/netcdf-cf.html) | Necessary | Familiarity with metadata structure |\n",
    "| [Intro to Xarray](https://foundations.projectpythia.org/core/xarray.html) | Necessary | |\n",
    "\n",
    "- **Time to learn**: 20 min\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Begin your body of content with another `---` divider before continuing into this section, then remove this body text and populate the following code cell with all necessary Python imports **up-front**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import urllib3\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "from cmocean import cm as cmo\n",
    "\n",
    "from argovisHelpers import helpers as avh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Downloading with the GO-BGC Toolbox\n",
    "\n",
    "In the previous notebook, [Introduction to Argo](notebooks/argo-introduction.ipynb), we saw how Argo synthetic profile ('[sprof](https://archimer.ifremer.fr/doc/00445/55637/)') data is stored in netcdf4 format.\n",
    "\n",
    "Using the GDAC function allows you to subset and download Sprof's for multiple floats. \n",
    "We recommend this tool for users who only need a few profilesd in a specific area of interest. \n",
    "Considerations: \n",
    "- Easy to use and understand\n",
    "- Downloads float data as individual .nc files to your local machine (takes up storage space)\n",
    "- Must download all variables available (cannot subset only variables of interest)\n",
    "\n",
    "The two major functions below are courtesy of the [GO-BGC Toolbox](https://github.com/go-bgc/workshop-python) (Ethan Campbell). A full tutorial is available in the Toolbox.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Base filepath. Need for Argo GDAC function.z\n",
    "# root = '/Users/sangminsong/Library/CloudStorage/OneDrive-UW/Code/2024_Pythia/'\n",
    "# profile_dir = root + 'SOCCOM_GO-BGC_LoResQC_LIAR_28Aug2023_netcdf/'\n",
    "\n",
    "# # Base filepath. Need for Argo GDAC function.\n",
    "root = '../data/'\n",
    "profile_dir = root + 'bgc-argo/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 GO-BGC Toolbox Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download a single file (From GO-BGC Toolbox)\n",
    "def download_file(url_path,filename,save_to=None,overwrite=False,verbose=True):\n",
    "    \"\"\" Downloads and saves a file from a given URL using HTTP protocol.\n",
    "\n",
    "    Note: If '404 file not found' error returned, function will return without downloading anything.\n",
    "    \n",
    "    Arguments:\n",
    "        url_path: root URL to download from including trailing slash ('/')\n",
    "        filename: filename to download including suffix\n",
    "        save_to: None (to download to root Google Drive GO-BGC directory)\n",
    "                 or directory path\n",
    "        overwrite: False to leave existing files in place\n",
    "                   or True to overwrite existing files\n",
    "        verbose: True to announce progress\n",
    "                 or False to stay silent\n",
    "    \n",
    "    \"\"\"\n",
    "    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "    if save_to is None:\n",
    "      save_to = root #profile_dir  # EDITED HERE\n",
    "\n",
    "    try:\n",
    "      if filename in os.listdir(save_to):\n",
    "          if not overwrite:\n",
    "              if verbose: print('>>> File ' + filename + ' already exists. Leaving current version.')\n",
    "              return\n",
    "          else:\n",
    "              if verbose: print('>>> File ' + filename + ' already exists. Overwriting with new version.')\n",
    "\n",
    "      def get_func(url,stream=True):\n",
    "          try:\n",
    "              return requests.get(url,stream=stream,auth=None,verify=False)\n",
    "          except requests.exceptions.ConnectionError as error_tag:\n",
    "              print('Error connecting:',error_tag)\n",
    "              time.sleep(1)\n",
    "              return get_func(url,stream=stream)\n",
    "\n",
    "      response = get_func(url_path + filename,stream=True)\n",
    "\n",
    "      if response.status_code == 404:\n",
    "          if verbose: print('>>> File ' + filename + ' returned 404 error during download.')\n",
    "          return\n",
    "      with open(save_to + filename,'wb') as out_file:\n",
    "          shutil.copyfileobj(response.raw,out_file)\n",
    "      del response\n",
    "      if verbose: print('>>> Successfully downloaded ' + filename + '.')\n",
    "\n",
    "    except:\n",
    "      if verbose: print('>>> An error occurred while trying to download ' + filename + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download and parse GDAC synthetic profile index file (GO-BGC Toolbox)\n",
    "def argo_gdac(lat_range=None,lon_range=None,start_date=None,end_date=None,sensors=None,floats=None,\n",
    "              overwrite_index=False,overwrite_profiles=False,skip_download=False,\n",
    "              download_individual_profs=False,save_to=None,verbose=True):\n",
    "  \"\"\" Downloads GDAC Sprof index file, then selects float profiles based on criteria.\n",
    "      Either returns information on profiles and floats (if skip_download=True) or downloads them (if False).\n",
    "\n",
    "      Arguments:\n",
    "          lat_range: None, to select all latitudes\n",
    "                     or [lower, upper] within -90 to 90 (selection is inclusive)\n",
    "          lon_range: None, to select all longitudes\n",
    "                     or [lower, upper] within either -180 to 180 or 0 to 360 (selection is inclusive)\n",
    "                     NOTE: longitude range is allowed to cross -180/180 or 0/360\n",
    "          start_date: None or datetime object\n",
    "          end_date:   None or datetime object\n",
    "          sensors: None, to select profiles with any combination of sensors\n",
    "                   or string or list of strings to specify required sensors\n",
    "                   > note that common options include PRES, TEMP, PSAL, DOXY, CHLA, BBP700,\n",
    "                                                      PH_IN_SITU_TOTAL, and NITRATE\n",
    "          floats: None, to select any floats matching other criteria\n",
    "                  or int or list of ints specifying floats' WMOID numbers\n",
    "          overwrite_index: False to keep existing downloaded GDAC index file, or True to download new index\n",
    "          overwrite_profiles: False to keep existing downloaded profile files, or True to download new files\n",
    "          skip_download: True to skip download and return: (, ,\n",
    "                                                            )\n",
    "                         or False to download those profiles\n",
    "          download_individual_profs: False to download single Sprof file containing all profiles for each float\n",
    "                                     or True to download individual profile files for each float\n",
    "          save_to: None to download to Google Drive \"/GO-BGC Workshop/Profiles\" directory\n",
    "                   or string to specify directory path for profile downloads\n",
    "          verbose: True to announce progress, or False to stay silent\n",
    "\n",
    "  \"\"\"\n",
    "  # Paths\n",
    "  url_root = 'https://www.usgodae.org/ftp/outgoing/argo/'\n",
    "  dac_url_root = url_root + 'dac/'\n",
    "  index_filename = 'argo_synthetic-profile_index.txt'\n",
    "  if save_to is None: save_to = root\n",
    "\n",
    "  # Download GDAC synthetic profile index file\n",
    "  download_file(url_root,index_filename,overwrite=overwrite_index)\n",
    "\n",
    "  # Load index file into Pandas DataFrame\n",
    "  gdac_index = pd.read_csv(root + index_filename,delimiter=',',header=8,parse_dates=['date','date_update'],\n",
    "                          date_parser=lambda x: pd.to_datetime(x,format='%Y%m%d%H%M%S'))\n",
    "\n",
    "  # Establish time and space criteria\n",
    "  if lat_range is None:  lat_range = [-90.0,90.0]\n",
    "  if lon_range is None:  lon_range = [-180.0,180.0]\n",
    "  elif lon_range[0] > 180 or lon_range[1] > 180:\n",
    "    if lon_range[0] > 180: lon_range[0] -= 360\n",
    "    if lon_range[1] > 180: lon_range[1] -= 360\n",
    "  if start_date is None: start_date = datetime(1900,1,1)\n",
    "  if end_date is None:   end_date = datetime(2200,1,1)\n",
    "\n",
    "  float_wmoid_regexp = r'[a-z]*/[0-9]*/profiles/[A-Z]*([0-9]*)_[0-9]*[A-Z]*.nc'\n",
    "  gdac_index['wmoid'] = gdac_index['file'].str.extract(float_wmoid_regexp).astype(int)\n",
    "  filepath_main_regexp = '([a-z]*/[0-9]*/)profiles/[A-Z]*[0-9]*_[0-9]*[A-Z]*.nc'\n",
    "  gdac_index['filepath_main'] = gdac_index['file'].str.extract(filepath_main_regexp)\n",
    "  filepath_regexp = '([a-z]*/[0-9]*/profiles/)[A-Z]*[0-9]*_[0-9]*[A-Z]*.nc'\n",
    "  gdac_index['filepath'] = gdac_index['file'].str.extract(filepath_regexp)\n",
    "  filename_regexp = '[a-z]*/[0-9]*/profiles/([A-Z]*[0-9]*_[0-9]*[A-Z]*.nc)'\n",
    "  gdac_index['filename'] = gdac_index['file'].str.extract(filename_regexp)\n",
    "\n",
    "  # Subset profiles based on time and space criteria\n",
    "  gdac_index_subset = gdac_index.loc[np.logical_and.reduce([gdac_index['latitude'] >= lat_range[0],\n",
    "                                                            gdac_index['latitude'] <= lat_range[1],\n",
    "                                                            gdac_index['date'] >= start_date,\n",
    "                                                            gdac_index['date'] <= end_date]),:]\n",
    "  if lon_range[1] >= lon_range[0]:    # range does not cross -180/180 or 0/360\n",
    "    gdac_index_subset = gdac_index_subset.loc[np.logical_and(gdac_index_subset['longitude'] >= lon_range[0],\n",
    "                                                             gdac_index_subset['longitude'] <= lon_range[1])]\n",
    "  elif lon_range[1] < lon_range[0]:   # range crosses -180/180 or 0/360\n",
    "    gdac_index_subset = gdac_index_subset.loc[np.logical_or(gdac_index_subset['longitude'] >= lon_range[0],\n",
    "                                                            gdac_index_subset['longitude'] <= lon_range[1])]\n",
    "\n",
    "  # If requested, subset profiles using float WMOID criteria\n",
    "  if floats is not None:\n",
    "    if type(floats) is not list: floats = [floats]\n",
    "    gdac_index_subset = gdac_index_subset.loc[gdac_index_subset['wmoid'].isin(floats),:]\n",
    "\n",
    "  # If requested, subset profiles using sensor criteria\n",
    "  if sensors is not None:\n",
    "    if type(sensors) is not list: sensors = [sensors]\n",
    "    for sensor in sensors:\n",
    "      gdac_index_subset = gdac_index_subset.loc[gdac_index_subset['parameters'].str.contains(sensor),:]\n",
    "\n",
    "  # Examine subsetted profiles\n",
    "  wmoids = gdac_index_subset['wmoid'].unique()\n",
    "  wmoid_filepaths = gdac_index_subset['filepath_main'].unique()\n",
    "\n",
    "  # Just return list of floats and DataFrame with subset of index file, or download each profile\n",
    "  if not skip_download:\n",
    "    downloaded_filenames = []\n",
    "    if download_individual_profs:\n",
    "      for p_idx in gdac_index_subset.index:\n",
    "        download_file(dac_url_root + gdac_index_subset.loc[p_idx]['filepath'],\n",
    "                      gdac_index_subset.loc[p_idx]['filename'],\n",
    "                      save_to=save_to,overwrite=overwrite_profiles,verbose=verbose)\n",
    "        downloaded_filenames.append(gdac_index_subset.loc[p_idx]['filename'])\n",
    "    else:\n",
    "      for f_idx, wmoid_filepath in enumerate(wmoid_filepaths):\n",
    "        download_file(dac_url_root + wmoid_filepath,str(wmoids[f_idx]) + '_Sprof.nc',\n",
    "                      save_to=save_to,overwrite=overwrite_profiles,verbose=verbose)\n",
    "        downloaded_filenames.append(str(wmoids[f_idx]) + '_Sprof.nc')\n",
    "    return wmoids, gdac_index_subset, downloaded_filenames\n",
    "  else:\n",
    "    return wmoids, gdac_index_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Using GDAC function to access Argo subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont download, just get wmoids\n",
    "# wmoids, gdac_index = argo_gdac(lat_range=lat_bounds,lon_range=lon_bounds,\n",
    "#                                start_date=start_yd,end_date=end_yd,\n",
    "#                                sensors=None,floats=None,\n",
    "#                                overwrite_index=True,overwrite_profiles=False,\n",
    "#                                skip_download=True,download_individual_profs=False,\n",
    "#                                save_to=profile_dir,verbose=True)\n",
    "\n",
    "# download specific float #5906030 \n",
    "wmoids, gdac_index, downloaded_filenames \\\n",
    "                   = argo_gdac(lat_range=None,lon_range=None,\n",
    "                               start_date=None,end_date=None,\n",
    "                               sensors=None,floats=5906030,\n",
    "                               overwrite_index=True,overwrite_profiles=False,\n",
    "                               skip_download=False,download_individual_profs=False,\n",
    "                               save_to=profile_dir,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSdict = {}\n",
    "# for filename in os.listdir(profile_dir):\n",
    "#     if filename.endswith(\".nc\"):\n",
    "#         fp = profile_dir + filename\n",
    "#         single_dataset = xr.open_dataset(fp, decode_times=False)\n",
    "#         DSdict[filename[0:7]] = single_dataset\n",
    "# # DSdict['5906030']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using the Argopy Python Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Querying Data with Argovis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Argovis provides an API that allows us to interact with Argo data while only downloading the exact subsets of data needed for analysis. \n",
    "Our examples here are modified from the [tutorial notebooks](https://github.com/argovis/demo_notebooks) released by Argovis. We showcase only a few of the functionalities, but more information can be found in the previous link.\n",
    "\n",
    "The introduction published by Argovis:\n",
    ">\"Argovis is a REST API and web application for searching, downloading, co-locating and visualizing oceanographic data, including Argo array data, ship-based profile data, data from the Global Drifter Program, tropical cyclone data, and several gridded products. Our API is meant to be integrated into living documents like Jupyter notebooks and analyses intended to update their consumption of Argo data in near-real-time, and our web frontend is intended to make it easy for students and educators to explore data about Earth's oceans at will.\"\n",
    "\n",
    "Argovis should be cited as:\n",
    "\n",
    "Tucker, T., D. Giglio, M. Scanderbeg, and S.S.P. Shen: Argovis: A Web Application for Fast Delivery, Visualization, and Analysis of Argo Data. J. Atmos. Oceanic Technol., 37, 401–416, https://doi.org/10.1175/JTECH-D-19-0041.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started with `argovisHelpers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Argovis tutorial: \n",
    "> In order to allocate Argovis's limited computing resources fairly, users are encouraged to register and request a free API key. This works like a password that identifies your requests to Argovis. To do so:\n",
    ">\n",
    "> - Visit [https://argovis-keygen.colorado.edu/](https://argovis-keygen.colorado.edu/)\n",
    "> - Fill out the form under _New Account Registration_\n",
    "> - An API key will be emailed to you shortly.\n",
    ">\n",
    "> Treat this API key like a password - don't share it or leave it anywhere public. If you ever forget it or accidentally reveal it to a third party, see the same website above to change or deactivate your token.\n",
    ">\n",
    "> Put your API key in the quotes in the variable below before moving on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_ROOT='https://argovis-api.colorado.edu/'\n",
    "API_KEY='de6ee72a54bc5ca29dee5c801cab13fa4a354985'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Argo data documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before actually getting Argo measurements, we can query information about the profile (including pointers to the metadata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1901820_256',\n",
       " 'geolocation': {'type': 'Point', 'coordinates': [-22.75594, -0.2218]},\n",
       " 'basin': 1,\n",
       " 'timestamp': '2023-04-09T18:34:30.001Z',\n",
       " 'date_updated_argovis': '2023-07-14T10:44:14.125Z',\n",
       " 'source': [{'source': ['argo_core'],\n",
       "   'url': 'ftp://ftp.ifremer.fr/ifremer/argo/dac/aoml/1901820/profiles/R1901820_256.nc',\n",
       "   'date_updated': '2023-07-13T22:33:14.000Z'}],\n",
       " 'cycle_number': 256,\n",
       " 'geolocation_argoqc': 1,\n",
       " 'profile_direction': 'A',\n",
       " 'timestamp_argoqc': 1,\n",
       " 'vertical_sampling_scheme': 'Primary sampling: averaged [nominal 2 dbar binned data sampled at 0.5 Hz from a SBE41CP]',\n",
       " 'data_info': [['pressure',\n",
       "   'pressure_argoqc',\n",
       "   'salinity',\n",
       "   'salinity_argoqc',\n",
       "   'temperature',\n",
       "   'temperature_argoqc'],\n",
       "  ['units', 'data_keys_mode'],\n",
       "  [['decibar', 'A'],\n",
       "   [None, None],\n",
       "   ['psu', 'A'],\n",
       "   [None, None],\n",
       "   ['degree_Celsius', 'A'],\n",
       "   [None, None]]],\n",
       " 'metadata': ['1901820_m0']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argoSearch = {\n",
    "    'startDate': '2013-05-01T00:00:00Z',\n",
    "    'endDate': '2023-05-01T00:00:00Z',\n",
    "    'center': '-22.5,0',\n",
    "    'radius': 100\n",
    "}\n",
    "\n",
    "argoProfiles = avh.query('argo', options=argoSearch, apikey=API_KEY, apiroot=API_ROOT)\n",
    "argoProfiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1901820_256'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argoProfiles[0]['_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first object in argoProfiles is a single vertical Argo \"profile\". \n",
    "The first 7 digits of `argoProfiles[0]['_id']` refer to a float's WMO unique identification number. \n",
    "The last three digits are the profile number. \n",
    "\n",
    "In the above example, we are looking at data from the 256th profile from float WMO #1901820."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get more information about this particular float by querying `argo/meta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': '1901820_m0',\n",
       "  'data_type': 'oceanicProfile',\n",
       "  'data_center': 'AO',\n",
       "  'instrument': 'profiling_float',\n",
       "  'pi_name': ['BRECK OWENS', ' STEVEN JAYNE', ' P.E. ROBBINS'],\n",
       "  'platform': '1901820',\n",
       "  'platform_type': 'S2A',\n",
       "  'fleetmonitoring': 'https://fleetmonitoring.euro-argo.eu/float/1901820',\n",
       "  'oceanops': 'https://www.ocean-ops.org/board/wa/Platform?ref=1901820',\n",
       "  'positioning_system': 'GPS',\n",
       "  'wmo_inst_type': '854'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaOptions = {\n",
    "    'id': argoProfiles[0]['metadata'][0]\n",
    "}\n",
    "argoMeta = avh.query('argo/meta', options=metaOptions, apikey=API_KEY, apiroot=API_ROOT)\n",
    "argoMeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify all of the profiles taken from the same float with WMO ID 1901820."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\n"
     ]
    }
   ],
   "source": [
    "platformSearch = {\n",
    "    'platform': argoMeta[0]['platform']\n",
    "}\n",
    "\n",
    "platformProfiles = avh.query('argo', options=platformSearch, apikey=API_KEY, apiroot=API_ROOT)\n",
    "print(len(platformProfiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making `data` queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to retrieve actual measurements. We can use any number of identifiers. \n",
    "\n",
    "Below, we are specifying float WMO 4901283 and profile #003. The `data` variable can be:\n",
    "\n",
    "- A comma separated list of variable names, e.g. `'temperature, doxy'`\n",
    "- `'all'`, meaning get all available variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataQuery = {\n",
    "    'id': '4901283_003',\n",
    "    'data': 'all'\n",
    "}\n",
    "profile = avh.query('argo', options=dataQuery, apikey=API_KEY, apiroot=API_ROOT)\n",
    "# avh.data_inflate(profile[0])[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query float profiles within larger bounds: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataQuery = {\n",
    "    'startDate': '2020-01-01T00:00:00Z',\n",
    "    'endDate': '2024-01-01T00:00:00Z',\n",
    "    'polygon': [[-150,-30],[-155,-30],[-155,-35],[-150,-35],[-150,-30]],\n",
    "    'data': 'doxy'\n",
    "}\n",
    "\n",
    "profiles = avh.query('argo', options=dataQuery, apikey=API_KEY, apiroot=API_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doxy': 235.335724, 'pressure': 7.6},\n",
       " {'doxy': 235.327026, 'pressure': 13.07},\n",
       " {'doxy': 235.418045, 'pressure': 17.720001},\n",
       " {'doxy': 235.212158, 'pressure': 22.02},\n",
       " {'doxy': 235.242828, 'pressure': 26.68},\n",
       " {'doxy': 235.235306, 'pressure': 31.320002},\n",
       " {'doxy': 235.273743, 'pressure': 36.709999},\n",
       " {'doxy': 235.165115, 'pressure': 41.73},\n",
       " {'doxy': 235.16153, 'pressure': 48.260002},\n",
       " {'doxy': 235.032471, 'pressure': 54.619999}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inflated_data = avh.data_inflate(profiles[0])\n",
    "inflated_data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying within geospatial bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = {\n",
    "    'startDate': '2017-08-01T00:00:00Z',\n",
    "    'endDate': '2017-09-01T00:00:00Z',\n",
    "    'box': [[-20,70],[20,72]]\n",
    "}\n",
    "\n",
    "profiles = avh.query('argo', options=qs, apikey=API_KEY, apiroot=API_ROOT)\n",
    "latitudes = [x['geolocation']['coordinates'][1] for x in profiles]\n",
    "print(min(latitudes))\n",
    "print(max(latitudes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsection to the second section\n",
    "\n",
    "#### a quick demonstration\n",
    "\n",
    "##### of further and further\n",
    "\n",
    "###### header levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as well $m = a * t / h$ text! Similarly, you have access to other $\\LaTeX$ equation [**functionality**](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Typesetting%20Equations.html) via MathJax (demo below from link),\n",
    "\n",
    "\\begin{align}\n",
    "\\dot{x} & = \\sigma(y-x) \\\\\n",
    "\\dot{y} & = \\rho x - y - xz \\\\\n",
    "\\dot{z} & = -\\beta z + xy\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out [**any number of helpful Markdown resources**](https://www.markdownguide.org/basic-syntax/) for further customizing your notebooks and the [**Jupyter docs**](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html) for Jupyter-specific formatting information. Don't hesitate to ask questions if you have problems getting it to look *just right*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Section\n",
    "\n",
    "If you're comfortable, and as we briefly used for our embedded logo up top, you can embed raw html into Jupyter Markdown cells (edit to see):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Info</p>\n",
    "    Your relevant information here!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to copy this around and edit or play around with yourself. Some other `admonitions` you can put in:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-success\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Success</p>\n",
    "    We got this done after all!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-warning\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Warning</p>\n",
    "    Be careful!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-danger\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Danger</p>\n",
    "    Scary stuff be here.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also suggest checking out Jupyter Book's [brief demonstration](https://jupyterbook.org/content/metadata.html#jupyter-cell-tags) on adding cell tags to your cells in Jupyter Notebook, Lab, or manually. Using these cell tags can allow you to [customize](https://jupyterbook.org/interactive/hiding.html) how your code content is displayed and even [demonstrate errors](https://jupyterbook.org/content/execute.html#dealing-with-code-that-raises-errors) without altogether crashing our loyal army of machines!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Add one final `---` marking the end of your body of content, and then conclude with a brief single paragraph summarizing at a high level the key pieces that were learned and how they tied to your objectives. Look to reiterate what the most important takeaways were.\n",
    "\n",
    "### What's next?\n",
    "Let Jupyter book tie this to the next (sequential) piece of content that people could move on to down below and in the sidebar. However, if this page uniquely enables your reader to tackle other nonsequential concepts throughout this book, or even external content, link to it here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources and references\n",
    "Finally, be rigorous in your citations and references as necessary. Give credit where credit is due. Also, feel free to link to relevant external material, further reading, documentation, etc. Then you're done! Give yourself a quick review, a high five, and send us a pull request. A few final notes:\n",
    " - `Kernel > Restart Kernel and Run All Cells...` to confirm that your notebook will cleanly run from start to finish\n",
    " - `Kernel > Restart Kernel and Clear All Outputs...` before committing your notebook, our machines will do the heavy lifting\n",
    " - Take credit! Provide author contact information if you'd like; if so, consider adding information here at the bottom of your notebook\n",
    " - Give credit! Attribute appropriate authorship for referenced code, information, images, etc.\n",
    " - Only include what you're legally allowed: **no copyright infringement or plagiarism**\n",
    " \n",
    "Thank you for your contribution!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python 3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ]
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
